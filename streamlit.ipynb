{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import os\n",
    "if socket.gethostname() == 'mv-gb03':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bouyang/RLAIF-V\n"
     ]
    }
   ],
   "source": [
    "%cd RLAIF-V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple, https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/simple\n",
      "Collecting datasets\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/60/2d/963b266bb8f88492d5ab4232d74292af8beb5b6fdae97902df9e284d4c32/datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp (from datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/a0/09/e7637f4f0760cad4d67347bbd8311c6ad0259a3fc01f04555af9e84bd378/aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.2 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (0.24.0)\n",
      "Requirement already satisfied: packaging in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/ec/25/0c87df2e53c0c5d90f7517ca0ff7aca78d050a8ec4d32c4278e8c0e52e51/frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/33/62/2c9085e571318d51212a6914566fe41dd0e33d7f268f7e2f23dcd3f06c56/multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/c3/a0/0ade1409d184cbc9e85acd403a386a7c0563b92ff0f26d138ff9e86e48b4/yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading https://sc-artifactory1.esperanto.ai/artifactory/api/pypi/pypi-virtual/packages/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "rlaif-v 1.0.0 requires huggingface-hub==0.17.0, but you have huggingface-hub 0.24.0 which is incompatible.\n",
      "rlaif-v 1.0.0 requires packaging==24.0, but you have packaging 23.2 which is incompatible.\n",
      "rlaif-v 1.0.0 requires Requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
      "rlaif-v 1.0.0 requires tqdm==4.66.1, but you have tqdm 4.66.4 which is incompatible.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.5.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-hotfix-0.6 requests-2.32.3 tqdm-4.66.4 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-25 16:54:35,152] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-07-25 16:54:36,542] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "Detected CUDA_VISIBLE_DEVICES=1: setting --include=localhost:1\n",
      "[2024-07-25 16:54:36,594] [INFO] [runner.py:570:main] cmd = /mnt/datascience3/Boya/miniconda3/envs/rlaifv/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ./muffin/train/train_llava15.py --deepspeed ./script/zero2.json --model_name_or_path liuhaotian/llava-v1.5-7b --data_dir ./RLAIF-V-Dataset_logps/ --image_folder not_used --vision_tower openai/clip-vit-large-patch14-336 --mm_use_im_start_end False --mm_use_im_patch_token False --fully_tune True --image_aspect_ratio pad --bf16 True --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --output_dir .ckpt/llava15_7b_DPO-llava15_rlaifv/checkpoints --num_train_epochs 10 --per_device_train_batch_size 1 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 167 --save_total_limit 50 --data_source_names  --data_source_weights 1 --max_steps 2672 --learning_rate 5e-7 --weight_decay 0.01 --warmup_ratio 0.05 --lr_scheduler_type cosine --logging_steps 2 --logging_dir .ckpt/llava15_7b_DPO-llava15_rlaifv/log --tf32 True --model_max_length 2048 --gradient_checkpointing True --lazy_preprocess True --task DPO --report_to wandb --run_name llava15_rlaifv --dataloader_num_workers 16 --dpo_use_average False --dpo_token_weighted False --dpo_token_weight 1.0 --dpo_beta 0.1\n",
      "[2024-07-25 16:54:38,116] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-07-25 16:54:39,406] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [1]}\n",
      "[2024-07-25 16:54:39,406] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-07-25 16:54:39,406] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-07-25 16:54:39,406] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-07-25 16:54:39,406] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=1\n",
      "[2024-07-25 16:54:42,428] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-07-25 16:54:44,268] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-07-25 16:54:44,268] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:05<00:00,  2.72s/it]\n",
      "conv template: Conversation(system=\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\", roles=('USER', 'ASSISTANT'), messages=(), offset=0, sep_style=<SeparatorStyle.TWO: 2>, sep=' ', sep2='</s>', version='v1', skip_next=False)\n",
      "No grad params are : []\n",
      "Downloading readme: 100%|██████████████████| 5.04k/5.04k [00:00<00:00, 29.8MB/s]\n",
      "Downloading data: 100%|████████████████████| 1.11G/1.11G [00:12<00:00, 92.1MB/s]\n",
      "Downloading data: 100%|████████████████████| 1.09G/1.09G [00:10<00:00, 99.0MB/s]\n",
      "Downloading data: 100%|███████████████████████| 970M/970M [00:09<00:00, 103MB/s]\n",
      "Downloading data: 100%|███████████████████████| 971M/971M [00:09<00:00, 102MB/s]\n",
      "Downloading data: 100%|██████████████████████| 856M/856M [00:08<00:00, 96.9MB/s]\n",
      "Downloading data: 100%|███████████████████████| 755M/755M [00:07<00:00, 101MB/s]\n",
      "Downloading data: 100%|██████████████████████| 897M/897M [00:39<00:00, 22.5MB/s]\n",
      "Downloading data: 100%|██████████████████████| 868M/868M [00:28<00:00, 30.0MB/s]\n",
      "Downloading data: 100%|████████████████████| 1.00G/1.00G [00:21<00:00, 46.1MB/s]\n",
      "Downloading data: 100%|███████████████████████| 828M/828M [00:07<00:00, 105MB/s]\n",
      "Downloading data: 100%|██████████████████████| 962M/962M [00:09<00:00, 99.7MB/s]\n",
      "Downloading data: 100%|███████████████████████| 853M/853M [00:07<00:00, 107MB/s]\n",
      "Downloading data: 100%|██████████████████████| 826M/826M [00:10<00:00, 76.0MB/s]\n",
      "Downloading data: 100%|██████████████████████| 726M/726M [00:10<00:00, 71.8MB/s]\n",
      "Generating train split: 83132 examples [00:25, 3248.16 examples/s]\n",
      "  1%|▍                                    | 866/83132 [02:40<4:08:00,  5.53it/s]^C\n",
      "[2024-07-25 17:02:13,565] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1024395\n"
     ]
    }
   ],
   "source": [
    "!bash ./script/train/llava15_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.20.10.37:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://12.251.228.10:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[AYou are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:08<00:08,  8.05s/it]\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.41s/it]\u001b[A\u001b[A\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.03s/it]\u001b[A\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.47s/it]\u001b[A\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:06<00:06,  6.09s/it]/mnt/datascience3/Boya/miniconda3/envs/rlaifv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:08<00:00,  4.21s/it]\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:09<00:00,  4.69s/it]\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlaifv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
